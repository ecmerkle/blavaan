<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Cross-loadings with strong priors • blavaan</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Cross-loadings with strong priors">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">blavaan</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.5-8.1360</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-basics" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Basics</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-basics">
<li><a class="dropdown-item" href="../articles/start.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/prior.html">Prior Specification</a></li>
    <li><a class="dropdown-item" href="../articles/estimate.html">Estimation</a></li>
    <li><a class="dropdown-item" href="../articles/convergence_efficiency.html">Convergence and Efficiency Evaluation</a></li>
    <li><a class="dropdown-item" href="../articles/summaries.html">Model Summaries</a></li>
    <li><a class="dropdown-item" href="../articles/plotting.html">Plots</a></li>
  </ul>
</li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples-details" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples/Details</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples-details">
<li><a class="dropdown-item" href="../articles/ordinal.html">Estimation with Ordinal Data</a></li>
    <li><a class="dropdown-item" href="../articles/multilevel.html">Two-level Estimation</a></li>
    <li><a class="dropdown-item" href="../articles/invariance.html">Measurement Invariance</a></li>
    <li><a class="dropdown-item" href="../articles/approx_fi.html">Approximate Fit Indices</a></li>
    <li><a class="dropdown-item" href="../articles/model_comparison.html">Model Comparison</a></li>
    <li><a class="dropdown-item" href="../articles/cross_loadings_strong_priors.html">Cross-loadings with Strong Priors</a></li>
    <li><a class="dropdown-item" href="../articles/mod_indices.html">Modification Indices</a></li>
    <li><a class="dropdown-item" href="../articles/prior_pred_checks.html">Prior Predictive Checks</a></li>
    <li><a class="dropdown-item" href="../articles/convergence_loop.html">Convergence Loop</a></li>
    <li><a class="dropdown-item" href="../articles/probability_direction.html">Probability of Direction</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">News</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/resources.html">Resources</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ecmerkle/blavaan"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://groups.google.com/d/forum/blavaan"><span class="fa fa-users"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Cross-loadings with strong priors</h1>
                        <h4 data-toc-skip class="author">Mauricio
Garnier-Villarreal</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ecmerkle/blavaan/blob/master/vignettes/cross_loadings_strong_priors.Rmd" class="external-link"><code>vignettes/cross_loadings_strong_priors.Rmd</code></a></small>
      <div class="d-none name"><code>cross_loadings_strong_priors.Rmd</code></div>
    </div>

    
    
<div class="section level3">
<h3 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h3>
<p>An advantage of BSEM is that we can use priors to set up
<strong>soft</strong> constraints in the model, by estimating a
parameter with a strong prior. This way the parameter is estimated, but
the prior will restrict the possible values.</p>
<p>This was suggested by <span class="citation">Muthén and Asparouhov
(2012)</span>, as a way to estimate all possible cross-loadings in a
CFA. This way, if the posterior distribution of the restricted
parameters includes values outside of the strong prior, it can be
interpreted as a model modification. This means that the parameters
should be less restricted, or that the prior distribution should be
relaxed.</p>
<p>In this tutorial we present how to estimate a CFA where all possible
cross-loadings are restricted by strong priors.</p>
</div>
<div class="section level3">
<h3 id="cross-loadings">Cross-loadings<a class="anchor" aria-label="anchor" href="#cross-loadings"></a>
</h3>
<p>We will show an example with the <span class="citation">Holzinger and
Swineford (1939)</span> data. First we will estimate the regular model
with no cross-loadings and default priors.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">HS.model</span> <span class="op">&lt;-</span> <span class="st">' visual  =~ x1 + x2 + x3</span></span>
<span><span class="st">              textual =~ x4 + x5 + x6</span></span>
<span><span class="st">              speed   =~ x7 + x8 + x9 '</span></span>
<span></span>
<span><span class="va">fit_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bcfa.html">bcfa</a></span><span class="op">(</span><span class="va">HS.model</span>, data<span class="op">=</span><span class="va">HolzingerSwineford1939</span>, </span>
<span>            std.lv<span class="op">=</span><span class="cn">TRUE</span>, meanstructure<span class="op">=</span><span class="cn">T</span><span class="op">)</span></span></code></pre></div>
<p>We can see the overall model results with the <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code>
function, looking at the posterior distribution for the factor loadings,
correlations, intercepts and variances.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit_df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## blavaan 0.5.8.1360 ended normally after 1000 iterations</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Estimator                                      BAYES</span></span>
<span><span class="co">##   Optimization method                             MCMC</span></span>
<span><span class="co">##   Number of model parameters                        30</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Number of observations                           301</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Statistic                                 MargLogLik         PPP</span></span>
<span><span class="co">##   Value                                      -3871.000       0.000</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Parameter Estimates:</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Latent Variables:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##   visual =~                                                                    </span></span>
<span><span class="co">##     x1                0.910    0.087    0.746    1.083    1.000    normal(0,10)</span></span>
<span><span class="co">##     x2                0.500    0.082    0.343    0.661    0.999    normal(0,10)</span></span>
<span><span class="co">##     x3                0.662    0.079    0.508    0.819    1.000    normal(0,10)</span></span>
<span><span class="co">##   textual =~                                                                   </span></span>
<span><span class="co">##     x4                1.001    0.058    0.891    1.118    1.000    normal(0,10)</span></span>
<span><span class="co">##     x5                1.114    0.063    0.993    1.241    1.000    normal(0,10)</span></span>
<span><span class="co">##     x6                0.927    0.054    0.822    1.035    1.001    normal(0,10)</span></span>
<span><span class="co">##   speed =~                                                                     </span></span>
<span><span class="co">##     x7                0.616    0.077    0.460    0.761    1.001    normal(0,10)</span></span>
<span><span class="co">##     x8                0.733    0.079    0.579    0.889    1.001    normal(0,10)</span></span>
<span><span class="co">##     x9                0.680    0.081    0.524    0.843    1.001    normal(0,10)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Covariances:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##   visual ~~                                                                    </span></span>
<span><span class="co">##     textual           0.450    0.065    0.315    0.572    1.000     lkj_corr(1)</span></span>
<span><span class="co">##     speed             0.463    0.087    0.290    0.627    1.000     lkj_corr(1)</span></span>
<span><span class="co">##   textual ~~                                                                   </span></span>
<span><span class="co">##     speed             0.279    0.072    0.132    0.416    1.000     lkj_corr(1)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Intercepts:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##    .x1                4.936    0.067    4.802    5.064    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x2                6.088    0.067    5.958    6.221    0.999    normal(0,32)</span></span>
<span><span class="co">##    .x3                2.250    0.065    2.125    2.377    0.999    normal(0,32)</span></span>
<span><span class="co">##    .x4                3.059    0.067    2.931    3.183    1.001    normal(0,32)</span></span>
<span><span class="co">##    .x5                4.341    0.074    4.195    4.488    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x6                2.185    0.063    2.062    2.307    0.999    normal(0,32)</span></span>
<span><span class="co">##    .x7                4.185    0.062    4.063    4.303    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x8                5.526    0.059    5.412    5.641    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x9                5.374    0.058    5.260    5.490    1.000    normal(0,32)</span></span>
<span><span class="co">##     visual            0.000                                                    </span></span>
<span><span class="co">##     textual           0.000                                                    </span></span>
<span><span class="co">##     speed             0.000                                                    </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Variances:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##    .x1                0.555    0.127    0.292    0.792    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x2                1.149    0.105    0.956    1.361    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x3                0.859    0.100    0.673    1.058    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x4                0.379    0.049    0.287    0.479    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x5                0.455    0.060    0.347    0.580    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x6                0.363    0.046    0.281    0.458    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x7                0.821    0.092    0.654    1.010    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x8                0.502    0.096    0.313    0.694    1.001 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x9                0.567    0.096    0.369    0.743    1.001 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     visual            1.000                                                    </span></span>
<span><span class="co">##     textual           1.000                                                    </span></span>
<span><span class="co">##     speed             1.000</span></span></code></pre>
<p>Next, we will add all possible cross-loadings with a strong prior of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>σ</mi><mo>=</mo><mn>0.08</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N(0, \sigma = 0.08)</annotation></semantics></math>.
The prior centers the loadings around 0 and allows them little space to
move.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">HS.model.cl</span><span class="op">&lt;-</span><span class="st">' visual  =~ x1 + x2 + x3</span></span>
<span><span class="st">              textual =~ x4 + x5 + x6</span></span>
<span><span class="st">              speed   =~ x7 + x8 + x9 </span></span>
<span><span class="st">    </span></span>
<span><span class="st">              ## Cross-loadings</span></span>
<span><span class="st">              visual =~  prior("normal(0,.08)")*x4 + prior("normal(0,.08)")*x5 + prior("normal(0,.08)")*x6 + prior("normal(0,.08)")*x7 + prior("normal(0,.08)")*x8 + prior("normal(0,.08)")*x9</span></span>
<span><span class="st">              textual =~ prior("normal(0,.08)")*x1 + prior("normal(0,.08)")*x2 + prior("normal(0,.08)")*x3 + prior("normal(0,.08)")*x7 + prior("normal(0,.08)")*x8 + prior("normal(0,.08)")*x9 </span></span>
<span><span class="st">              speed =~ prior("normal(0,.08)")*x1 + prior("normal(0,.08)")*x2 + prior("normal(0,.08)")*x3 + prior("normal(0,.08)")*x4 + prior("normal(0,.08)")*x5 + prior("normal(0,.08)")*x6'</span></span>
<span></span>
<span><span class="va">fit_cl</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bcfa.html">bcfa</a></span><span class="op">(</span><span class="va">HS.model.cl</span>, data<span class="op">=</span><span class="va">HolzingerSwineford1939</span>, </span>
<span>            std.lv<span class="op">=</span><span class="cn">TRUE</span>, meanstructure<span class="op">=</span><span class="cn">T</span><span class="op">)</span></span></code></pre></div>
<p>It is important that, for each factor, the first variable after
<code>=~</code> is one whose loading we expect to be far from 0. So, in
the above model, we specified the regular cfa first (whose loadings we
expect to be larger), then the loadings with small-variance priors on a
separate line. This is important because, in blavaan, the first loading
is either constrained to be positive or fixed to 1 (depending on
<code>std.lv</code>). If the posterior distribution of that constrained
loading is centered near 0, we may experience identification problems.
Reverse-coded variables can also be problematic here, because a positive
constraint on a reverse-coded loading can lead other loadings to assume
negative values. If you use informative priors in this situation, then
you should verify that the prior density is on the correct side of
0.</p>
<p>After estimation, you can look at the <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> of this
model and evaluate the cross-loadings. You can specifically see whether
any of the cross-loadings seem large enough to suggest that they should
be kept in the model, by looking at the posterior mean
(<code>Estimate</code>) and credible interval.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit_cl</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## blavaan 0.5.8.1360 ended normally after 1000 iterations</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Estimator                                      BAYES</span></span>
<span><span class="co">##   Optimization method                             MCMC</span></span>
<span><span class="co">##   Number of model parameters                        48</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Number of observations                           301</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Statistic                                 MargLogLik         PPP</span></span>
<span><span class="co">##   Value                                      -3858.968       0.130</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Parameter Estimates:</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Latent Variables:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##   visual =~                                                                    </span></span>
<span><span class="co">##     x1                0.763    0.098    0.578    0.966    1.000    normal(0,10)</span></span>
<span><span class="co">##     x2                0.568    0.092    0.388    0.749    1.000    normal(0,10)</span></span>
<span><span class="co">##     x3                0.766    0.097    0.576    0.954    1.000    normal(0,10)</span></span>
<span><span class="co">##   textual =~                                                                   </span></span>
<span><span class="co">##     x4                0.983    0.064    0.862    1.113    1.000    normal(0,10)</span></span>
<span><span class="co">##     x5                1.155    0.070    1.022    1.295    0.999    normal(0,10)</span></span>
<span><span class="co">##     x6                0.894    0.061    0.776    1.014    0.999    normal(0,10)</span></span>
<span><span class="co">##   speed =~                                                                     </span></span>
<span><span class="co">##     x7                0.730    0.085    0.564    0.899    0.999    normal(0,10)</span></span>
<span><span class="co">##     x8                0.790    0.082    0.629    0.951    1.000    normal(0,10)</span></span>
<span><span class="co">##     x9                0.545    0.073    0.406    0.687    1.000    normal(0,10)</span></span>
<span><span class="co">##   visual =~                                                                    </span></span>
<span><span class="co">##     x4                0.033    0.058   -0.081    0.145    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x5               -0.073    0.064   -0.199    0.057    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x6                0.063    0.054   -0.044    0.165    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x7               -0.132    0.065   -0.258   -0.003    1.001   normal(0,.08)</span></span>
<span><span class="co">##     x8               -0.007    0.066   -0.136    0.120    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x9                0.192    0.061    0.070    0.311    1.001   normal(0,.08)</span></span>
<span><span class="co">##   textual =~                                                                   </span></span>
<span><span class="co">##     x1                0.109    0.064   -0.022    0.229    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x2                0.007    0.059   -0.110    0.121    0.999   normal(0,.08)</span></span>
<span><span class="co">##     x3               -0.085    0.062   -0.207    0.038    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x7                0.016    0.061   -0.108    0.128    1.001   normal(0,.08)</span></span>
<span><span class="co">##     x8               -0.038    0.061   -0.153    0.081    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x9                0.032    0.055   -0.078    0.139    1.001   normal(0,.08)</span></span>
<span><span class="co">##   speed =~                                                                     </span></span>
<span><span class="co">##     x1                0.041    0.063   -0.088    0.164    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x2               -0.050    0.062   -0.171    0.068    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x3                0.029    0.064   -0.098    0.147    0.999   normal(0,.08)</span></span>
<span><span class="co">##     x4               -0.004    0.056   -0.113    0.107    1.000   normal(0,.08)</span></span>
<span><span class="co">##     x5                0.008    0.062   -0.114    0.135    0.999   normal(0,.08)</span></span>
<span><span class="co">##     x6                0.000    0.055   -0.109    0.103    0.999   normal(0,.08)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Covariances:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##   visual ~~                                                                    </span></span>
<span><span class="co">##     textual           0.376    0.094    0.181    0.548    0.999     lkj_corr(1)</span></span>
<span><span class="co">##     speed             0.358    0.110    0.125    0.555    1.000     lkj_corr(1)</span></span>
<span><span class="co">##   textual ~~                                                                   </span></span>
<span><span class="co">##     speed             0.258    0.102    0.051    0.451    1.000     lkj_corr(1)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Intercepts:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##    .x1                4.936    0.067    4.807    5.068    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x2                6.089    0.068    5.958    6.220    0.999    normal(0,32)</span></span>
<span><span class="co">##    .x3                2.250    0.064    2.122    2.374    0.999    normal(0,32)</span></span>
<span><span class="co">##    .x4                3.061    0.069    2.928    3.197    1.001    normal(0,32)</span></span>
<span><span class="co">##    .x5                4.340    0.076    4.190    4.491    1.001    normal(0,32)</span></span>
<span><span class="co">##    .x6                2.185    0.064    2.059    2.312    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x7                4.186    0.064    4.058    4.313    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x8                5.527    0.059    5.411    5.644    1.000    normal(0,32)</span></span>
<span><span class="co">##    .x9                5.375    0.057    5.261    5.487    1.001    normal(0,32)</span></span>
<span><span class="co">##     visual            0.000                                                    </span></span>
<span><span class="co">##     textual           0.000                                                    </span></span>
<span><span class="co">##     speed             0.000                                                    </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Variances:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       </span></span>
<span><span class="co">##    .x1                0.678    0.109    0.457    0.879    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x2                1.088    0.109    0.891    1.314    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x3                0.716    0.112    0.493    0.938    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x4                0.388    0.049    0.299    0.491    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x5                0.412    0.063    0.297    0.541    0.999 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x6                0.373    0.044    0.291    0.465    0.999 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x7                0.711    0.094    0.526    0.888    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x8                0.439    0.090    0.253    0.611    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##    .x9                0.587    0.066    0.465    0.728    1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     visual            1.000                                                    </span></span>
<span><span class="co">##     textual           1.000                                                    </span></span>
<span><span class="co">##     speed             1.000</span></span></code></pre>
<p>We suggest to not simply look at whether the CI excludes 0 (similar
to the null hypothesis), but to evaluate whether the minimum value of
the CI (the value closer to 0) is far enough away from 0 to be relavant
instead of just <strong>different</strong> from 0.</p>
</div>
<div class="section level3">
<h3 id="caveats">Caveats<a class="anchor" aria-label="anchor" href="#caveats"></a>
</h3>
<p>The model with all possible cross-loadings should not be kept as the
final analysis model, but should be used as a step to make decisions
about model changes. This for two main reasons, (1) this model is
overfitted and would present <em>good</em> overall fit just due to the
inclusion of a lot of nuisance parameters. In this example the posterior
predictive p-value goes from ppp = 0 to ppp = 0.13, and is not that the
model is better theoretically but that we are inflating the model fit.
And (2), the addition of small-variance priors can prevent detection of
important misspecifications in Bayesian confirmatory factor analysis, as
it can obscure underlying problems in the model by diluting it through a
large number of nuisance parameters <span class="citation">(Jorgensen et
al. 2019)</span>.</p>
</div>
<div class="section level3 unnumbered">
<h3 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-holswi39" class="csl-entry">
Holzinger, K. J., and F. A. Swineford. 1939. <em>A Study of Factor
Analysis: <span>T</span>he Stability of a Bi-Factor Solution</em>.
Supplementary Educational Monograph 48. Chicago: University of Chicago
Press.
</div>
<div id="ref-jorgensen_small_variance_2019" class="csl-entry">
Jorgensen, Terrence D, Mauricio Garnier-Villarreal, Sunthud
Pornprasertmanit, and Jaehoon Lee. 2019. <span>“Small-Variance Priors
Can Prevent Detecting Important Misspecifications in
<span>Bayesian</span> Confirmatory Factor Analysis.”</span> In
<em>Quantitative Psychology: <span>The</span> 83rd Annual Meeting of the
<span>Psychometric</span> <span>Society</span>, <span>New</span>
<span>York</span>, <span>NY</span>, 2018</em>, edited by Marie Wiberg,
Steven Culpepper, Rianne Janssen, Jorge González, and Dylan Molenaar,
265:255–63. Springer <span>Proceedings</span> in
<span>Mathematics</span> &amp; <span>Statistics</span>. New York, NY,
US: Springer. <a href="https://doi.org/10.1007/978-3-030-01310-3_23" class="external-link">https://doi.org/10.1007/978-3-030-01310-3_23</a>.
</div>
<div id="ref-muthen_bayesian_2012" class="csl-entry">
Muthén, Bengt, and Tihomir Asparouhov. 2012. <span>“Bayesian Structural
Equation Modeling: <span>A</span> More Flexible Representation of
Substantive Theory.”</span> <em>Psychological Methods</em> 17 (3):
313–35. <a href="https://doi.org/10.1037/a0026802" class="external-link">https://doi.org/10.1037/a0026802</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Edgar Merkle, Yves Rosseel, Ben Goodrich.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>

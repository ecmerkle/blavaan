<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Probability of Direction • blavaan</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Probability of Direction">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">blavaan</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.5-5.1296</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-basics" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Basics</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-basics">
<li><a class="dropdown-item" href="../articles/start.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/prior.html">Prior Specification</a></li>
    <li><a class="dropdown-item" href="../articles/estimate.html">Estimation</a></li>
    <li><a class="dropdown-item" href="../articles/convergence_efficiency.html">Convergence and Efficiency Evaluation</a></li>
    <li><a class="dropdown-item" href="../articles/summaries.html">Model Summaries</a></li>
    <li><a class="dropdown-item" href="../articles/plotting.html">Plots</a></li>
  </ul>
</li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples-details" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples/Details</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples-details">
<li><a class="dropdown-item" href="../articles/ordinal.html">Estimation with Ordinal Data</a></li>
    <li><a class="dropdown-item" href="../articles/multilevel.html">Two-level Estimation</a></li>
    <li><a class="dropdown-item" href="../articles/invariance.html">Measurement Invariance</a></li>
    <li><a class="dropdown-item" href="../articles/approx_fi.html">Approximate Fit Indices</a></li>
    <li><a class="dropdown-item" href="../articles/model_comparison.html">Model Comparison</a></li>
    <li><a class="dropdown-item" href="../articles/cross_loadings_strong_priors.html">Cross-loadings with Strong Priors</a></li>
    <li><a class="dropdown-item" href="../articles/mod_indices.html">Modification Indices</a></li>
    <li><a class="dropdown-item" href="../articles/prior_pred_checks.html">Prior Predictive Checks</a></li>
    <li><a class="dropdown-item" href="../articles/convergence_loop.html">Convergence Loop</a></li>
    <li><a class="dropdown-item" href="../articles/probability_direction.html">Probability of Direction</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">News</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/resources.html">Resources</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ecmerkle/blavaan"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://groups.google.com/d/forum/blavaan"><span class="fa fa-users"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Probability of Direction</h1>
                        <h4 data-toc-skip class="author">Mauricio
Garnier-Villarreal</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ecmerkle/blavaan/blob/master/vignettes/probability_direction.Rmd" class="external-link"><code>vignettes/probability_direction.Rmd</code></a></small>
      <div class="d-none name"><code>probability_direction.Rmd</code></div>
    </div>

    
    
<div class="section level3">
<h3 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h3>
<p>The Probability of Direction (pd) is an index of effect existence,
ranging from 0% to 100%, representing the certainty with which an effect
goes in a particular direction (i.e., is positive or negative) <span class="citation">(Makowski et al. 2019)</span>. Beyond its simplicity of
interpretation, understanding and computation, this index also presents
other interesting properties: <em>It is independent from the model: It
is solely based on the posterior distributions and does not require any
additional information from the data or the model. </em>It is robust to
the scale of both the response variable and the predictors. *It is
strongly correlated with the frequentist p-value, and can thus be used
to draw parallels and give some reference to readers non-familiar with
Bayesian statistics.</p>
<p>Can be interpreted as the probability that a parameter (described by
its posterior distribution) is above or below a chosen cutoff, an
explicit hypothesis. It is mathematically defined as the proportion of
the posterior distribution that satisfies the specified hypothesis.
Although differently expressed, this index is fairly similar (i.e., is
strongly correlated) to the frequentist p-value.</p>
</div>
<div class="section level3">
<h3 id="probability-of-direction-pd">Probability of Direction (pd)<a class="anchor" aria-label="anchor" href="#probability-of-direction-pd"></a>
</h3>
<p>For this example we will use the Industrialization and Political
Democracy example <span class="citation">(Bollen 1989)</span>. We will
first estimate the latent regression model</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="st">'</span></span>
<span><span class="st">  # latent variable definitions</span></span>
<span><span class="st">     ind60 =~ x1 + x2 + x3</span></span>
<span><span class="st">     dem60 =~ a*y1 + b*y2 + c*y3 + d*y4</span></span>
<span><span class="st">     dem65 =~ a*y5 + b*y6 + c*y7 + d*y8</span></span>
<span><span class="st"></span></span>
<span><span class="st">  # regressions</span></span>
<span><span class="st">    dem60 ~ ind60</span></span>
<span><span class="st">    dem65 ~ ind60 + dem60</span></span>
<span><span class="st"></span></span>
<span><span class="st">  # residual correlations</span></span>
<span><span class="st">    y1 ~~ y5</span></span>
<span><span class="st">    y2 ~~ y4 + y6</span></span>
<span><span class="st">    y3 ~~ y7</span></span>
<span><span class="st">    y4 ~~ y8</span></span>
<span><span class="st">    y6 ~~ y8</span></span>
<span><span class="st">'</span></span>
<span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bsem.html">bsem</a></span><span class="op">(</span><span class="va">model</span>, data<span class="op">=</span><span class="va">PoliticalDemocracy</span>,</span>
<span>            std.lv<span class="op">=</span><span class="cn">T</span>, meanstructure<span class="op">=</span><span class="cn">T</span><span class="op">)</span></span></code></pre></div>
<p>We can then look at the overall model results with the
<code>summary</code> function, in this case we are also asking for the
standardized estimates, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math></p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit</span>, standardize<span class="op">=</span><span class="cn">T</span>, rsquare<span class="op">=</span><span class="cn">T</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## blavaan 0.5.5.1296 ended normally after 1000 iterations</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Estimator                                      BAYES</span></span>
<span><span class="co">##   Optimization method                             MCMC</span></span>
<span><span class="co">##   Number of model parameters                        42</span></span>
<span><span class="co">##   Number of equality constraints                     4</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Number of observations                            75</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Statistic                                 MargLogLik         PPP</span></span>
<span><span class="co">##   Value                                             NA       0.022</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Parameter Estimates:</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Latent Variables:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper   Std.lv  Std.all</span></span>
<span><span class="co">##   ind60 =~                                                              </span></span>
<span><span class="co">##     x1                0.705    0.071    0.579    0.859    0.705    0.922</span></span>
<span><span class="co">##     x2                1.533    0.139    1.285    1.831    1.533    0.972</span></span>
<span><span class="co">##     x3                1.273    0.139    1.018    1.575    1.273    0.872</span></span>
<span><span class="co">##   dem60 =~                                                              </span></span>
<span><span class="co">##     y1         (a)    1.460    0.172    1.139    1.807    1.786    0.762</span></span>
<span><span class="co">##     y2         (b)    1.729    0.222    1.312    2.198    2.115    0.584</span></span>
<span><span class="co">##     y3         (c)    1.815    0.200    1.429    2.222    2.220    0.701</span></span>
<span><span class="co">##     y4         (d)    1.946    0.192    1.599    2.333    2.380    0.789</span></span>
<span><span class="co">##   dem65 =~                                                              </span></span>
<span><span class="co">##     y5         (a)    1.460    0.172    1.139    1.807    2.300    0.811</span></span>
<span><span class="co">##     y6         (b)    1.729    0.222    1.312    2.198    2.724    0.769</span></span>
<span><span class="co">##     y7         (c)    1.815    0.200    1.429    2.222    2.859    0.837</span></span>
<span><span class="co">##     y8         (d)    1.946    0.192    1.599    2.333    3.065    0.870</span></span>
<span><span class="co">##      Rhat    Prior       </span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     1.000    normal(0,10)</span></span>
<span><span class="co">##     1.001    normal(0,10)</span></span>
<span><span class="co">##     1.001    normal(0,10)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     1.000    normal(0,10)</span></span>
<span><span class="co">##     1.000    normal(0,10)</span></span>
<span><span class="co">##     1.000    normal(0,10)</span></span>
<span><span class="co">##     1.000    normal(0,10)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     1.000                </span></span>
<span><span class="co">##     1.000                </span></span>
<span><span class="co">##     1.000                </span></span>
<span><span class="co">##     1.000                </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Regressions:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper   Std.lv  Std.all</span></span>
<span><span class="co">##   dem60 ~                                                               </span></span>
<span><span class="co">##     ind60             0.704    0.169    0.389    1.051    0.576    0.576</span></span>
<span><span class="co">##   dem65 ~                                                               </span></span>
<span><span class="co">##     ind60             0.248    0.177   -0.106    0.588    0.158    0.158</span></span>
<span><span class="co">##     dem60             0.865    0.127    0.623    1.114    0.671    0.671</span></span>
<span><span class="co">##      Rhat    Prior       </span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     1.000    normal(0,10)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     0.999    normal(0,10)</span></span>
<span><span class="co">##     1.000    normal(0,10)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Covariances:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper   Std.lv  Std.all</span></span>
<span><span class="co">##  .y1 ~~                                                                 </span></span>
<span><span class="co">##    .y5                0.757    0.441   -0.013    1.720    0.757    0.300</span></span>
<span><span class="co">##  .y2 ~~                                                                 </span></span>
<span><span class="co">##    .y4                1.773    0.844    0.342    3.733    1.773    0.325</span></span>
<span><span class="co">##    .y6                2.220    0.785    0.810    3.918    2.220    0.333</span></span>
<span><span class="co">##  .y3 ~~                                                                 </span></span>
<span><span class="co">##    .y7                1.309    0.705    0.040    2.888    1.309    0.310</span></span>
<span><span class="co">##  .y4 ~~                                                                 </span></span>
<span><span class="co">##    .y8                0.372    0.495   -0.534    1.448    0.372    0.116</span></span>
<span><span class="co">##  .y6 ~~                                                                 </span></span>
<span><span class="co">##    .y8                1.094    0.712   -0.209    2.613    1.094    0.278</span></span>
<span><span class="co">##      Rhat    Prior       </span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     1.000       beta(1,1)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     1.000       beta(1,1)</span></span>
<span><span class="co">##     0.999       beta(1,1)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     0.999       beta(1,1)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     1.000       beta(1,1)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##     0.999       beta(1,1)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Intercepts:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper   Std.lv  Std.all</span></span>
<span><span class="co">##    .x1                5.056    0.089    4.881    5.230    5.056    6.615</span></span>
<span><span class="co">##    .x2                4.798    0.182    4.447    5.155    4.798    3.043</span></span>
<span><span class="co">##    .x3                3.559    0.171    3.237    3.900    3.559    2.438</span></span>
<span><span class="co">##    .y1                5.465    0.276    4.913    5.988    5.465    2.331</span></span>
<span><span class="co">##    .y2                4.252    0.420    3.427    5.104    4.252    1.173</span></span>
<span><span class="co">##    .y3                6.562    0.365    5.837    7.253    6.562    2.072</span></span>
<span><span class="co">##    .y4                4.448    0.346    3.782    5.116    4.448    1.475</span></span>
<span><span class="co">##    .y5                5.137    0.328    4.477    5.754    5.137    1.811</span></span>
<span><span class="co">##    .y6                2.981    0.406    2.178    3.752    2.981    0.842</span></span>
<span><span class="co">##    .y7                6.198    0.404    5.389    6.983    6.198    1.814</span></span>
<span><span class="co">##    .y8                4.044    0.409    3.252    4.853    4.044    1.148</span></span>
<span><span class="co">##     ind60             0.000                               0.000    0.000</span></span>
<span><span class="co">##    .dem60             0.000                               0.000    0.000</span></span>
<span><span class="co">##    .dem65             0.000                               0.000    0.000</span></span>
<span><span class="co">##      Rhat    Prior       </span></span>
<span><span class="co">##     1.006    normal(0,32)</span></span>
<span><span class="co">##     1.006    normal(0,32)</span></span>
<span><span class="co">##     1.005    normal(0,32)</span></span>
<span><span class="co">##     1.003    normal(0,32)</span></span>
<span><span class="co">##     1.003    normal(0,32)</span></span>
<span><span class="co">##     1.001    normal(0,32)</span></span>
<span><span class="co">##     1.004    normal(0,32)</span></span>
<span><span class="co">##     1.002    normal(0,32)</span></span>
<span><span class="co">##     1.004    normal(0,32)</span></span>
<span><span class="co">##     1.005    normal(0,32)</span></span>
<span><span class="co">##     1.003    normal(0,32)</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Variances:</span></span>
<span><span class="co">##                    Estimate  Post.SD pi.lower pi.upper   Std.lv  Std.all</span></span>
<span><span class="co">##    .x1                0.087    0.023    0.047    0.136    0.087    0.149</span></span>
<span><span class="co">##    .x2                0.137    0.082    0.004    0.321    0.137    0.055</span></span>
<span><span class="co">##    .x3                0.511    0.100    0.346    0.734    0.511    0.240</span></span>
<span><span class="co">##    .y1                2.310    0.589    1.307    3.602    2.310    0.420</span></span>
<span><span class="co">##    .y2                8.664    1.575    5.980   12.231    8.664    0.660</span></span>
<span><span class="co">##    .y3                5.101    1.076    3.277    7.473    5.101    0.509</span></span>
<span><span class="co">##    .y4                3.427    0.923    1.814    5.455    3.427    0.377</span></span>
<span><span class="co">##    .y5                2.754    0.654    1.669    4.222    2.754    0.342</span></span>
<span><span class="co">##    .y6                5.122    1.037    3.333    7.340    5.122    0.408</span></span>
<span><span class="co">##    .y7                3.506    0.876    2.083    5.461    3.506    0.300</span></span>
<span><span class="co">##    .y8                3.020    0.877    1.425    4.968    3.020    0.243</span></span>
<span><span class="co">##     ind60             1.000                               1.000    1.000</span></span>
<span><span class="co">##    .dem60             1.000                               0.669    0.669</span></span>
<span><span class="co">##    .dem65             1.000                               0.403    0.403</span></span>
<span><span class="co">##      Rhat    Prior       </span></span>
<span><span class="co">##     1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     0.999 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     0.999 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     0.999 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     0.999 gamma(1,.5)[sd]</span></span>
<span><span class="co">##     1.000 gamma(1,.5)[sd]</span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">##                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## R-Square:</span></span>
<span><span class="co">##                    Estimate</span></span>
<span><span class="co">##     x1                0.851</span></span>
<span><span class="co">##     x2                0.945</span></span>
<span><span class="co">##     x3                0.760</span></span>
<span><span class="co">##     y1                0.580</span></span>
<span><span class="co">##     y2                0.340</span></span>
<span><span class="co">##     y3                0.491</span></span>
<span><span class="co">##     y4                0.623</span></span>
<span><span class="co">##     y5                0.658</span></span>
<span><span class="co">##     y6                0.592</span></span>
<span><span class="co">##     y7                0.700</span></span>
<span><span class="co">##     y8                0.757</span></span>
<span><span class="co">##     dem60             0.331</span></span>
<span><span class="co">##     dem65             0.597</span></span></code></pre>
<p>To calculate the probability of direction we will use a function from
the package <code>brms</code> <span class="citation">(Bürkner
2017)</span></p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paul-buerkner/brms" class="external-link">brms</a></span><span class="op">)</span></span></code></pre></div>
<p>And we will need to extract the posterior draws as a matrix,</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mc_out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="../reference/blavInspect.html">blavInspect</a></span><span class="op">(</span><span class="va">fit</span>, <span class="st">"mcmc"</span>, add.labels <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">mc_out</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3000   42</span></span></code></pre>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">mc_out</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  [1] "ly_sign[1]"    "ly_sign[2]"    "ly_sign[3]"    "ly_sign[4]"   </span></span>
<span><span class="co">##  [5] "ly_sign[5]"    "ly_sign[6]"    "ly_sign[7]"    "ly_sign[4]"   </span></span>
<span><span class="co">##  [9] "ly_sign[5]"    "ly_sign[6]"    "ly_sign[7]"    "bet_sign[1]"  </span></span>
<span><span class="co">## [13] "bet_sign[2]"   "bet_sign[3]"   "Theta_cov[1]"  "Theta_cov[2]" </span></span>
<span><span class="co">## [17] "Theta_cov[3]"  "Theta_cov[4]"  "Theta_cov[5]"  "Theta_cov[6]" </span></span>
<span><span class="co">## [21] "Theta_var[1]"  "Theta_var[2]"  "Theta_var[3]"  "Theta_var[4]" </span></span>
<span><span class="co">## [25] "Theta_var[5]"  "Theta_var[6]"  "Theta_var[7]"  "Theta_var[8]" </span></span>
<span><span class="co">## [29] "Theta_var[9]"  "Theta_var[10]" "Theta_var[11]" "Nu_free[1]"   </span></span>
<span><span class="co">## [33] "Nu_free[2]"    "Nu_free[3]"    "Nu_free[4]"    "Nu_free[5]"   </span></span>
<span><span class="co">## [37] "Nu_free[6]"    "Nu_free[7]"    "Nu_free[8]"    "Nu_free[9]"   </span></span>
<span><span class="co">## [41] "Nu_free[10]"   "Nu_free[11]"</span></span></code></pre>
<p>It is also important to note that the parameters in the posterior
draws are named after the <code>Stan</code> underlying object names,
instead of the <code>(b)lavaan</code> parameter names. This is due to
the argument <code>add.labels = FALSE</code> and is used here to avoid
trouble with parameter names that have tildes or equal signs in them.
You can see what each parameter name equates to with the
<code><a href="https://rdrr.io/pkg/lavaan/man/parTable.html" class="external-link">partable()</a></code> function, as follows</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lavaan/man/parTable.html" class="external-link">partable</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"lhs"</span>,<span class="st">"op"</span>,<span class="st">"rhs"</span>,<span class="st">"pxnames"</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">pt</span></span></code></pre></div>
<pre><code><span><span class="co">##      lhs op   rhs       pxnames</span></span>
<span><span class="co">## 1  ind60 =~    x1    ly_sign[1]</span></span>
<span><span class="co">## 2  ind60 =~    x2    ly_sign[2]</span></span>
<span><span class="co">## 3  ind60 =~    x3    ly_sign[3]</span></span>
<span><span class="co">## 4  dem60 =~    y1    ly_sign[4]</span></span>
<span><span class="co">## 5  dem60 =~    y2    ly_sign[5]</span></span>
<span><span class="co">## 6  dem60 =~    y3    ly_sign[6]</span></span>
<span><span class="co">## 7  dem60 =~    y4    ly_sign[7]</span></span>
<span><span class="co">## 8  dem65 =~    y5    ly_sign[4]</span></span>
<span><span class="co">## 9  dem65 =~    y6    ly_sign[5]</span></span>
<span><span class="co">## 10 dem65 =~    y7    ly_sign[6]</span></span>
<span><span class="co">## 11 dem65 =~    y8    ly_sign[7]</span></span>
<span><span class="co">## 12 dem60  ~ ind60   bet_sign[1]</span></span>
<span><span class="co">## 13 dem65  ~ ind60   bet_sign[2]</span></span>
<span><span class="co">## 14 dem65  ~ dem60   bet_sign[3]</span></span>
<span><span class="co">## 15    y1 ~~    y5  Theta_cov[1]</span></span>
<span><span class="co">## 16    y2 ~~    y4  Theta_cov[2]</span></span>
<span><span class="co">## 17    y2 ~~    y6  Theta_cov[3]</span></span>
<span><span class="co">## 18    y3 ~~    y7  Theta_cov[4]</span></span>
<span><span class="co">## 19    y4 ~~    y8  Theta_cov[5]</span></span>
<span><span class="co">## 20    y6 ~~    y8  Theta_cov[6]</span></span>
<span><span class="co">## 21    x1 ~~    x1  Theta_var[1]</span></span>
<span><span class="co">## 22    x2 ~~    x2  Theta_var[2]</span></span>
<span><span class="co">## 23    x3 ~~    x3  Theta_var[3]</span></span>
<span><span class="co">## 24    y1 ~~    y1  Theta_var[4]</span></span>
<span><span class="co">## 25    y2 ~~    y2  Theta_var[5]</span></span>
<span><span class="co">## 26    y3 ~~    y3  Theta_var[6]</span></span>
<span><span class="co">## 27    y4 ~~    y4  Theta_var[7]</span></span>
<span><span class="co">## 28    y5 ~~    y5  Theta_var[8]</span></span>
<span><span class="co">## 29    y6 ~~    y6  Theta_var[9]</span></span>
<span><span class="co">## 30    y7 ~~    y7 Theta_var[10]</span></span>
<span><span class="co">## 31    y8 ~~    y8 Theta_var[11]</span></span>
<span><span class="co">## 32 ind60 ~~ ind60          &lt;NA&gt;</span></span>
<span><span class="co">## 33 dem60 ~~ dem60          &lt;NA&gt;</span></span>
<span><span class="co">## 34 dem65 ~~ dem65          &lt;NA&gt;</span></span>
<span><span class="co">## 35    x1 ~1          Nu_free[1]</span></span>
<span><span class="co">## 36    x2 ~1          Nu_free[2]</span></span>
<span><span class="co">## 37    x3 ~1          Nu_free[3]</span></span>
<span><span class="co">## 38    y1 ~1          Nu_free[4]</span></span>
<span><span class="co">## 39    y2 ~1          Nu_free[5]</span></span>
<span><span class="co">## 40    y3 ~1          Nu_free[6]</span></span>
<span><span class="co">## 41    y4 ~1          Nu_free[7]</span></span>
<span><span class="co">## 42    y5 ~1          Nu_free[8]</span></span>
<span><span class="co">## 43    y6 ~1          Nu_free[9]</span></span>
<span><span class="co">## 44    y7 ~1         Nu_free[10]</span></span>
<span><span class="co">## 45    y8 ~1         Nu_free[11]</span></span>
<span><span class="co">## 46 ind60 ~1                &lt;NA&gt;</span></span>
<span><span class="co">## 47 dem60 ~1                &lt;NA&gt;</span></span>
<span><span class="co">## 48 dem65 ~1                &lt;NA&gt;</span></span>
<span><span class="co">## 49  .p4. ==  .p8.          &lt;NA&gt;</span></span>
<span><span class="co">## 50  .p5. ==  .p9.          &lt;NA&gt;</span></span>
<span><span class="co">## 51  .p6. == .p10.          &lt;NA&gt;</span></span>
<span><span class="co">## 52  .p7. == .p11.          &lt;NA&gt;</span></span></code></pre>
<p>For this example we will focus on the regressions between factors</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pt</span><span class="op">[</span><span class="va">pt</span><span class="op">$</span><span class="va">op</span><span class="op">==</span><span class="st">"~"</span>,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##      lhs op   rhs     pxnames</span></span>
<span><span class="co">## 12 dem60  ~ ind60 bet_sign[1]</span></span>
<span><span class="co">## 13 dem65  ~ ind60 bet_sign[2]</span></span>
<span><span class="co">## 14 dem65  ~ dem60 bet_sign[3]</span></span></code></pre>
<p>Now, we can calculate pd, with the <code><a href="https://paul-buerkner.github.io/brms/reference/hypothesis.brmsfit.html" class="external-link">hypothesis()</a></code> function
from <code>brms</code>. We can ask specific questions of the posterior
distributions, for example if we want to know what proportion of the
regression <code>dem65~ind60</code> is higher than 0. The function
requires 2 arguments, the posterior draws (<code>mc_out</code>) and a
hypothesis (<code>bet_sign[2] &gt; 0</code>). We are also adding the
``alpha``` argument that specifies the size for the credible
intervals</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/hypothesis.brmsfit.html" class="external-link">hypothesis</a></span><span class="op">(</span><span class="va">mc_out</span>, <span class="st">"bet_sign[2] &gt; 0"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## New names:</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...4`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...5`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...6`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...7`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...8`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...9`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...10`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...11`</span></span></code></pre>
<pre><code><span><span class="co">## Hypothesis Tests for class :</span></span>
<span><span class="co">##          Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob</span></span>
<span><span class="co">## 1 (bet_sign[2]) &gt; 0     0.25      0.18    -0.05     0.54       11.1      0.92</span></span>
<span><span class="co">##   Star</span></span>
<span><span class="co">## 1     </span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.</span></span>
<span><span class="co">## '*': For one-sided hypotheses, the posterior probability exceeds 95%;</span></span>
<span><span class="co">## for two-sided hypotheses, the value tested against lies outside the 95%-CI.</span></span>
<span><span class="co">## Posterior probabilities of point hypotheses assume equal prior probabilities.</span></span></code></pre>
<p>The estimate presents the mean of the posterior distribution, and the
respective measures of variability (deviation and credible interval).
<code>Post.Prob</code> is the pd under the stated hypothesis, so in this
example we can say that 91% of the posterior distribution of
<code>dem65~ind60</code> is lower than 0. This is equivalent to the
one-tail test. And <code>Evid.Ratio</code> is the evidence ratio for the
hypothesis, when the hypothesis is of the form
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>&gt;</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a &gt; b</annotation></semantics></math>,
the evidence ratio is the ratio of the posterior probability of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>&gt;</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a &gt; b</annotation></semantics></math>
and the posterior probability of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>&lt;</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a &lt; b</annotation></semantics></math></p>
<p>In another example, we want to know what proportion of the regression
<code>dem60~ind60</code> is higher than 0. Here we can see that 100% of
the posterior probability is higher than 0, in such a case
<code>Evid.Ratio = Inf</code>, this will happens when the whole
distribution fulfills the hypothesis.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/hypothesis.brmsfit.html" class="external-link">hypothesis</a></span><span class="op">(</span><span class="va">mc_out</span>, <span class="st">"bet_sign[1] &gt; 0"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## New names:</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...4`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...5`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...6`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...7`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...8`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...9`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...10`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...11`</span></span></code></pre>
<pre><code><span><span class="co">## Hypothesis Tests for class :</span></span>
<span><span class="co">##          Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob</span></span>
<span><span class="co">## 1 (bet_sign[1]) &gt; 0      0.7      0.17     0.44     0.99        Inf         1</span></span>
<span><span class="co">##   Star</span></span>
<span><span class="co">## 1    *</span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.</span></span>
<span><span class="co">## '*': For one-sided hypotheses, the posterior probability exceeds 95%;</span></span>
<span><span class="co">## for two-sided hypotheses, the value tested against lies outside the 95%-CI.</span></span>
<span><span class="co">## Posterior probabilities of point hypotheses assume equal prior probabilities.</span></span></code></pre>
<p>In another possible case of interest, you could use this to test
equalities between parameters, for example we can test if
<code>dem60~ind60</code> is higher than <code>dem65~ind60</code>. Here
we see 97% of the posteriors state that <code>dem60~ind60</code> is
higher than <code>dem65~ind60</code>, and the mean of the difference
(<code>dem60~ind60 - dem65~ind60</code>) is
<code>Estimate=0.46</code></p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/hypothesis.brmsfit.html" class="external-link">hypothesis</a></span><span class="op">(</span><span class="va">mc_out</span>, <span class="st">"bet_sign[1] - bet_sign[2] &gt; 0"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## New names:</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...4`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...5`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...6`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...7`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...8`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...9`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...10`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...11`</span></span></code></pre>
<pre><code><span><span class="co">## Hypothesis Tests for class :</span></span>
<span><span class="co">##                 Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio</span></span>
<span><span class="co">## 1 (bet_sign[1]-bet_... &gt; 0     0.46      0.25     0.06     0.88      39.54</span></span>
<span><span class="co">##   Post.Prob Star</span></span>
<span><span class="co">## 1      0.98    *</span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.</span></span>
<span><span class="co">## '*': For one-sided hypotheses, the posterior probability exceeds 95%;</span></span>
<span><span class="co">## for two-sided hypotheses, the value tested against lies outside the 95%-CI.</span></span>
<span><span class="co">## Posterior probabilities of point hypotheses assume equal prior probabilities.</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="region-of-practical-equivalence-rope">Region of Practical Equivalence (ROPE)<a class="anchor" aria-label="anchor" href="#region-of-practical-equivalence-rope"></a>
</h3>
<p>Note that so far we have only tested the hypothesis against 0, which
would be equivalent to the frequentist null hypothesis tests. But we can
test against any other. Bayesian inference is not based on statistical
significance, where effects are tested against “zero”. Indeed, the
Bayesian framework offers a probabilistic view of the parameters,
allowing assessment of the uncertainty related to them. Thus, rather
than concluding that an effect is present when it simply differs from
zero, we would conclude that the probability of being outside a specific
range that can be considered as “practically no effect” (i.e., a
negligible magnitude) is sufficient. This range is called the region of
practical equivalence (ROPE).</p>
<p>Indeed, statistically, the probability of a posterior distribution
being different from 0 does not make much sense (the probability of it
being different from a single point being infinite). Therefore, the idea
underlining ROPE is to let the user define an area around the null value
enclosing values that are equivalent to the null value for practical
purposes <span class="citation">(Kruschke and Liddell 2018)</span></p>
<p>For these examples, we would change the value tested, a common
recommendations is to use <code>|0.1|</code> as the minimally relevant
value for standardized regressions, in this case we find that
<code>0.79</code> proportion of the posterior is above
<code>0.1</code></p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/hypothesis.brmsfit.html" class="external-link">hypothesis</a></span><span class="op">(</span><span class="va">mc_out</span>, <span class="st">"bet_sign[2] &gt; .1"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## New names:</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...4`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...5`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...6`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...7`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[4]` -&gt; `ly_sign[4]...8`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[5]` -&gt; `ly_sign[5]...9`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[6]` -&gt; `ly_sign[6]...10`</span></span>
<span><span class="co">## <span style="color: #00BBBB;">•</span> `ly_sign[7]` -&gt; `ly_sign[7]...11`</span></span></code></pre>
<pre><code><span><span class="co">## Hypothesis Tests for class :</span></span>
<span><span class="co">##               Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio</span></span>
<span><span class="co">## 1 (bet_sign[2])-(.1) &gt; 0     0.15      0.18    -0.15     0.44       4.02</span></span>
<span><span class="co">##   Post.Prob Star</span></span>
<span><span class="co">## 1       0.8     </span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.</span></span>
<span><span class="co">## '*': For one-sided hypotheses, the posterior probability exceeds 95%;</span></span>
<span><span class="co">## for two-sided hypotheses, the value tested against lies outside the 95%-CI.</span></span>
<span><span class="co">## Posterior probabilities of point hypotheses assume equal prior probabilities.</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="vs--95-ci">89% vs. 95% CI<a class="anchor" aria-label="anchor" href="#vs--95-ci"></a>
</h3>
<p>Most commonly and from the frequentist tradition you will see the use
of the 95% Credible interval. Using 89% is another popular choice, and
used to be the default for a long time. How did it start?</p>
<p>Naturally, when it came about choosing the CI level to report by
default, people started using 95%, the arbitrary convention used in the
frequentist world. However, some authors suggested that 95% might not be
the most appropriate for Bayesian posterior distributions, potentially
lacking stability if not enough posterior samples are drawn <span class="citation">(McElreath 2020)</span>.</p>
<p>The proposition was to use 90% instead of 95%. However, recently,
<span class="citation">McElreath (2020)</span> suggested that if we were
to use arbitrary thresholds in the first place, why not use 89%?
Moreover, 89 is the highest prime number that does not exceed the
already unstable 95% threshold. What does it have to do with anything?
Nothing, but it reminds us of the total arbitrariness of these
conventions <span class="citation">(McElreath 2020)</span>.</p>
<p>You can use this as the argument <code>alpha</code> argument in the
<code>hypothesis</code> function, or as the interpretation values for
<code>Post.Prob</code></p>
</div>
<div class="section level3">
<h3 id="caveats">Caveats<a class="anchor" aria-label="anchor" href="#caveats"></a>
</h3>
<p>Although this allows testing of hypotheses in a similar manner as in
the frequentist null-hypothesis testing framework, we strongly argue
against using arbitrary cutoffs (e.g., p &lt; .05) to determine the
‘existence’ of an effect.</p>
<p>ROPE is sensitive to scale, so be aware that the value of interest is
representative in the respective scale. For this, standardize parameters
are useful to have in a commonly used scale</p>
</div>
<div class="section level3 unnumbered">
<h3 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-bollen_structural_1989" class="csl-entry">
Bollen, Kenneth A. 1989. <em>Structural <span>Equations</span> with
<span>Latent</span> <span>Variables</span></em>. Wiley Series in
Probability and Mathematical Statistics. John Wiley &amp; Sons, Inc.
</div>
<div id="ref-brms" class="csl-entry">
Bürkner, Paul-Christian. 2017. <span>“<span class="nocase">brms</span>:
An <span>R</span> Package for <span>Bayesian</span> Multilevel Models
Using <span>Stan</span>.”</span> <em>Journal of Statistical
Software</em> 80 (1): 1–28. <a href="https://doi.org/10.18637/jss.v080.i01" class="external-link">https://doi.org/10.18637/jss.v080.i01</a>.
</div>
<div id="ref-kruschke_bayesian_2018" class="csl-entry">
Kruschke, John K., and Torrin M. Liddell. 2018. <span>“The
<span>Bayesian</span> <span>New</span> <span>Statistics</span>:
<span>Hypothesis</span> Testing, Estimation, Meta-Analysis, and Power
Analysis from a <span>Bayesian</span> Perspective.”</span>
<em>Psychonomic Bulletin &amp; Review</em> 25 (1): 178–206. <a href="https://doi.org/10.3758/s13423-016-1221-4" class="external-link">https://doi.org/10.3758/s13423-016-1221-4</a>.
</div>
<div id="ref-makowski_indices_2019" class="csl-entry">
Makowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and
Daniel Lüdecke. 2019. <span>“Indices of <span>Effect</span>
<span>Existence</span> and <span>Significance</span> in the
<span>Bayesian</span> <span>Framework</span>.”</span> <em>Frontiers in
Psychology</em> 10: 2767. <a href="https://doi.org/10.3389/fpsyg.2019.02767" class="external-link">https://doi.org/10.3389/fpsyg.2019.02767</a>.
</div>
<div id="ref-mcelreath_statistical_2020" class="csl-entry">
McElreath, Richard. 2020. <em>Statistical Rethinking: A
<span>Bayesian</span> Course with Examples in <span>R</span> and
<span>Stan</span></em>. 2nd ed. <span>CRC</span> Texts in Statistical
Science. Boca Raton: Taylor; Francis, CRC Press.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Edgar Merkle, Yves Rosseel, Ben Goodrich.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
